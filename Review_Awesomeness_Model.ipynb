{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a99b21-db3c-44bc-ba47-c72d4a4f235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f76acec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/adenweiser/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca5b12a9-5bbc-4884-9edd-f0a75da71e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(path, test=False):\n",
    "    #start_time = time.time()\n",
    "    \n",
    "    #create appropriate file path\n",
    "    if test == False:\n",
    "        pfilename = path + \"/product_training.json\"\n",
    "        rfilename = path + \"/review_training.json\"\n",
    "    else:\n",
    "        pfilename = path + \"/product_test.json\"\n",
    "        rfilename = path + \"/review_test.json\"\n",
    "    \n",
    "    #extract files as pandas dataframes\n",
    "    product_df = pd.read_json(pfilename)\n",
    "    \n",
    "    review_df = pd.read_json(rfilename).drop_duplicates(subset=[\"reviewerID\", \"unixReviewTime\"], keep=\"first\")\n",
    "    ## 11.66 seconds to get to here\n",
    "    \n",
    "    review_df.drop(columns=[\"reviewerID\",\"vote\", \"unixReviewTime\",\"reviewTime\",\"style\",\"reviewerName\",\"image\"], axis=1 ,inplace=True)\n",
    "    \n",
    "    review_df['reviewText'].fillna(\"\", inplace=True)\n",
    "    review_df['summary'].fillna(\"\", inplace=True)\n",
    "    \n",
    "    review_df.sort_values('asin', inplace = True)\n",
    "    product_df.sort_values('asin', inplace = True)\n",
    "    \n",
    "    group = review_df.groupby(\"asin\")\n",
    "    \n",
    "    #review_group_df = pd.DataFrame(columns = ['asin', 'numReviews', 'percentVerified','reviewText','summaryText', 'awesomeness'])\n",
    "    \n",
    "    # about the same amount of time to get to here\n",
    "    start_time = time.time()\n",
    "    datalist = []\n",
    "    count = 0\n",
    "    #awesome_pos = 0\n",
    "    for asin, data in group:\n",
    "        verifiedCount = data['verified'].sum()\n",
    "        reviewCount = data['asin'].count()\n",
    "        percentVerified = verifiedCount / reviewCount\n",
    "        if count == 0:\n",
    "            print(type(data['reviewText']))\n",
    "        reviewText = ' '.join(data['reviewText'])\n",
    "        #reviewText = ' '.join(transform_document(x) for x in data['reviewText'])\n",
    "        #summaryText = \"\"\n",
    "        summaryText = ' '.join(data['summary'])\n",
    "        #summaryText = ' '.join(transform_document(x) for x in data['summary'])\n",
    "        #reviewText = transform_document(' '.join(data['reviewText']))\n",
    "        #summaryText = transform_document(' '.join(data['summary']))\n",
    "        #awesomeness = 0\n",
    "        \n",
    "        #SENTIMENT ANALYSIS CHUNK\n",
    "        (rev_mean, rev_stdev) = sentiment_analysis(data['reviewText'])\n",
    "        (sum_mean, sum_stdev) = sentiment_analysis(data['summary'])\n",
    "        while (product_df['asin'][count] != asin):\n",
    "               count = count + 1\n",
    "        \n",
    "        awesomeness = product_df['awesomeness'][count]\n",
    "        #awesome_pos = awesome_pos + reviewCount\n",
    "        #awesomeness = product_df.loc[product_df['asin'] == asin, 'awesomeness'].values[0] #might be slow\n",
    "        datalist.append([asin,  reviewCount, percentVerified, reviewText, summaryText, rev_mean, rev_stdev, sum_mean, sum_stdev, awesomeness])\n",
    "        \n",
    "        count = count + 1\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "        \n",
    "        '''new_row = {'asin': asin, \n",
    "                   'numReviews': reviewCount, \n",
    "                   'percentVerified': percentVerified, \n",
    "                   'reviewText': transform_document(' '.join(data['reviewText'])), \n",
    "                   'summaryText': transform_document(' '.join(data['summary'])), \n",
    "                   'awesomeness': product_df.loc[product_df['asin'] == asin, 'awesomeness'].values[0]} \n",
    "        review_group_df = review_group_df.append(new_row, ignore_index = True)\n",
    "         '''\n",
    "    review_group_df = pd.DataFrame(datalist,columns =['asin', 'numReviews', 'percentVerified','reviewText','summaryText', \\\n",
    "                                                      'reviewMean', 'reviewStDev', 'summaryMean', 'summaryStDev', 'awesomeness'])    \n",
    "    \n",
    "    review_group_df.to_json(r'../devided_dataset_v2/CDs_and_Vinyl/train/cleaned_data.json')\n",
    "    end_time = time.time()\n",
    "    print(end_time - start_time)\n",
    "    \n",
    "    return review_group_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c92fbe-6af3-432f-8a0a-fff1ea309c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>numReviews</th>\n",
       "      <th>percentVerified</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summaryText</th>\n",
       "      <th>reviewMean</th>\n",
       "      <th>reviewStDev</th>\n",
       "      <th>summaryMean</th>\n",
       "      <th>summaryStDev</th>\n",
       "      <th>awesomeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000B049F5B33CD310EB1AB236E20191</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Even tho I love this album, I am having proble...</td>\n",
       "      <td>I LOVE NANCY THE BEAUTIFUL LEGEND, NANCY WILSO...</td>\n",
       "      <td>1.969500</td>\n",
       "      <td>0.025729</td>\n",
       "      <td>1.487900</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018184A9EC4D270219A296B2580303</td>\n",
       "      <td>14</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>I have been a fan of GU's releases since i can...</td>\n",
       "      <td>One of GU's best The King of Progressive House...</td>\n",
       "      <td>1.710100</td>\n",
       "      <td>0.477970</td>\n",
       "      <td>1.208650</td>\n",
       "      <td>0.245517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000281A9CAC43FF1F335726A390636DA</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I made the mistake buying this album after lis...</td>\n",
       "      <td>Bad Business</td>\n",
       "      <td>1.285600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00030884DF109F325638A6BFD5B13CFF</td>\n",
       "      <td>20</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>Wow!  A must hear! Bob Marley at his best. Wha...</td>\n",
       "      <td>Maybe the Greatest Live Reggae Album Ever Bob ...</td>\n",
       "      <td>1.708190</td>\n",
       "      <td>0.440495</td>\n",
       "      <td>1.278090</td>\n",
       "      <td>0.336915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000325BA25966B5FC701D5D2B5DBA4E0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Soft, melodic notes dot moving waves of ethere...</td>\n",
       "      <td>Light Notes Robin Miller/Transcendence relaxin...</td>\n",
       "      <td>1.895167</td>\n",
       "      <td>0.106837</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.221703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71538</th>\n",
       "      <td>FFFDD3C72D23AF858D6E0ED92612370D</td>\n",
       "      <td>41</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>The bright yellow case on Kiss' sophomore albu...</td>\n",
       "      <td>'Cause baby's got the feeling, baby wants a sh...</td>\n",
       "      <td>1.774800</td>\n",
       "      <td>0.354987</td>\n",
       "      <td>1.227337</td>\n",
       "      <td>0.395480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71539</th>\n",
       "      <td>FFFDDE284A73B29B320381487EC7DE9E</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>I picked up this CD for about $6 US and I have...</td>\n",
       "      <td>A leisurely stroll through the country AN HONE...</td>\n",
       "      <td>1.949700</td>\n",
       "      <td>0.049274</td>\n",
       "      <td>1.168350</td>\n",
       "      <td>0.385339</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71540</th>\n",
       "      <td>FFFEB3EE2372807964F024707D50FB21</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Pop music has a short memory, but Kevin Roland...</td>\n",
       "      <td>A strong comeback by a troubled artist The 4th...</td>\n",
       "      <td>1.955100</td>\n",
       "      <td>0.051902</td>\n",
       "      <td>1.038600</td>\n",
       "      <td>0.054589</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71541</th>\n",
       "      <td>FFFF4545AB232D81D0F9B208388BB7AA</td>\n",
       "      <td>5</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>I ordered the album as soon as I stumbled it, ...</td>\n",
       "      <td>EXCELLENT concept album, but shouldn't be the ...</td>\n",
       "      <td>1.783980</td>\n",
       "      <td>0.331717</td>\n",
       "      <td>1.393140</td>\n",
       "      <td>0.293603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71542</th>\n",
       "      <td>FFFF5A3D9CB0B40FF0FE6B95F05D26FE</td>\n",
       "      <td>23</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>Opinions are funny things. Everyone has differ...</td>\n",
       "      <td>MAKE YOUR OWN DECISION few good songs Worse th...</td>\n",
       "      <td>1.268161</td>\n",
       "      <td>0.845806</td>\n",
       "      <td>1.038174</td>\n",
       "      <td>0.449628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71543 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   asin  numReviews  percentVerified  \\\n",
       "0      0000B049F5B33CD310EB1AB236E20191           3         0.666667   \n",
       "1      00018184A9EC4D270219A296B2580303          14         0.071429   \n",
       "2      000281A9CAC43FF1F335726A390636DA           1         0.000000   \n",
       "3      00030884DF109F325638A6BFD5B13CFF          20         0.550000   \n",
       "4      000325BA25966B5FC701D5D2B5DBA4E0           3         1.000000   \n",
       "...                                 ...         ...              ...   \n",
       "71538  FFFDD3C72D23AF858D6E0ED92612370D          41         0.341463   \n",
       "71539  FFFDDE284A73B29B320381487EC7DE9E           4         0.500000   \n",
       "71540  FFFEB3EE2372807964F024707D50FB21           2         1.000000   \n",
       "71541  FFFF4545AB232D81D0F9B208388BB7AA           5         0.600000   \n",
       "71542  FFFF5A3D9CB0B40FF0FE6B95F05D26FE          23         0.043478   \n",
       "\n",
       "                                              reviewText  \\\n",
       "0      Even tho I love this album, I am having proble...   \n",
       "1      I have been a fan of GU's releases since i can...   \n",
       "2      I made the mistake buying this album after lis...   \n",
       "3      Wow!  A must hear! Bob Marley at his best. Wha...   \n",
       "4      Soft, melodic notes dot moving waves of ethere...   \n",
       "...                                                  ...   \n",
       "71538  The bright yellow case on Kiss' sophomore albu...   \n",
       "71539  I picked up this CD for about $6 US and I have...   \n",
       "71540  Pop music has a short memory, but Kevin Roland...   \n",
       "71541  I ordered the album as soon as I stumbled it, ...   \n",
       "71542  Opinions are funny things. Everyone has differ...   \n",
       "\n",
       "                                             summaryText  reviewMean  \\\n",
       "0      I LOVE NANCY THE BEAUTIFUL LEGEND, NANCY WILSO...    1.969500   \n",
       "1      One of GU's best The King of Progressive House...    1.710100   \n",
       "2                                           Bad Business    1.285600   \n",
       "3      Maybe the Greatest Live Reggae Album Ever Bob ...    1.708190   \n",
       "4      Light Notes Robin Miller/Transcendence relaxin...    1.895167   \n",
       "...                                                  ...         ...   \n",
       "71538  'Cause baby's got the feeling, baby wants a sh...    1.774800   \n",
       "71539  A leisurely stroll through the country AN HONE...    1.949700   \n",
       "71540  A strong comeback by a troubled artist The 4th...    1.955100   \n",
       "71541  EXCELLENT concept album, but shouldn't be the ...    1.783980   \n",
       "71542  MAKE YOUR OWN DECISION few good songs Worse th...    1.268161   \n",
       "\n",
       "       reviewStDev  summaryMean  summaryStDev  awesomeness  \n",
       "0         0.025729     1.487900      0.433071            1  \n",
       "1         0.477970     1.208650      0.245517            0  \n",
       "2         0.000000     0.457700      0.000000            0  \n",
       "3         0.440495     1.278090      0.336915            1  \n",
       "4         0.106837     0.872000      0.221703            0  \n",
       "...            ...          ...           ...          ...  \n",
       "71538     0.354987     1.227337      0.395480            1  \n",
       "71539     0.049274     1.168350      0.385339            1  \n",
       "71540     0.051902     1.038600      0.054589            0  \n",
       "71541     0.331717     1.393140      0.293603            1  \n",
       "71542     0.845806     1.038174      0.449628            1  \n",
       "\n",
       "[71543 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessed Data Generated (Reviews and Summaries aggregated, no NLP processing)\n",
    "review_group_df = data_preprocessing(\"../devided_dataset_v2/CDs_and_Vinyl/train\")\n",
    "#review_group_df = pd.read_json('../devided_dataset_v2/CDs_and_Vinyl/train/cleaned_data.json')\n",
    "#review_group_df\n",
    "#review_group_df.to_json(\"preprocessed.json\")\n",
    "#review_group_df.head()\n",
    "#review_group_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663aa55a-fe39-4c15-a6cb-27f4fe073e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(docs):\n",
    "    sentiments = []\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    for doc in docs:\n",
    "        polarities = sid.polarity_scores(doc)\n",
    "        sentiments.append(polarities['compound'])\n",
    "    if len(sentiments) == 1:\n",
    "        return (sentiments[0], 0)\n",
    "    else:\n",
    "        return (statistics.mean(sentiments) + 1, statistics.stdev(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "473a32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_transformer = Pipeline(\n",
    "    steps = [('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer())]\n",
    ")\n",
    "wordbagger = ColumnTransformer(\n",
    "    transformers=[(\"rev\", string_transformer, 'reviewText'), \n",
    "                  (\"sum\", string_transformer, 'summaryText')]\n",
    "    , remainder='passthrough'\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps = [(\"wordbag\", wordbagger), \n",
    "                        (\"scale\", MaxAbsScaler()), \n",
    "                        ('classifier', RandomForestClassifier())])\n",
    "#x = review_group_df.filter(['numReviews', 'percentVerified', 'reviewText', 'summaryText'])\n",
    "#clf = LogisticRegression(tol = 0.001, max_iter = 150)\n",
    "#clf.fit(x,y)\n",
    "review_features = review_group_df.filter(['numReviews', 'percentVerified', 'reviewText', 'summaryText', 'reviewMean', 'reviewStDev', 'summaryMean', 'summaryStDev'])\n",
    "y = review_group_df.filter(['awesomeness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7a6713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I started at 1682714630.908139\n",
      "39.14513936837514\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"I started at \" + str(start))\n",
    "# this runs the k-fold cross-validation automatically?\n",
    "cv10_results = cross_validate(clf, review_features, np.ravel(y), cv=10, n_jobs = -1, scoring = ['f1_macro', 'precision', 'recall'])\n",
    "end = time.time()\n",
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f2d2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1573.13251805, 1579.55282402, 1579.21438384, 1597.68321085,\n",
      "       1583.75677896, 1578.28207994, 1598.66020703, 1593.00883818,\n",
      "        740.78515697,  739.19833899]), 'score_time': array([15.5390501 , 14.13390803, 13.83592224,  9.6982522 , 14.11366105,\n",
      "       14.00288701,  8.36288905,  9.00348902,  6.05653405,  6.30660605]), 'test_f1_macro': array([0.57882855, 0.57741459, 0.5854562 , 0.58193651, 0.58244206,\n",
      "       0.58275959, 0.57121476, 0.58086328, 0.58859251, 0.57945204]), 'test_precision': array([0.59479475, 0.59380306, 0.59961929, 0.5973831 , 0.59725115,\n",
      "       0.59749739, 0.58921933, 0.596255  , 0.60203649, 0.59514768]), 'test_recall': array([0.73993156, 0.73650961, 0.74624901, 0.73308765, 0.75493551,\n",
      "       0.75414583, 0.7509871 , 0.74598579, 0.74703869, 0.74275935])}\n",
      "0.5808960096461864\n",
      "0.004704425492159298\n",
      "0.5963007227741477\n",
      "0.003454509632326464\n",
      "0.7451630102486714\n",
      "0.00722133099383289\n"
     ]
    }
   ],
   "source": [
    "print(cv10_results)\n",
    "print(statistics.mean(cv10_results['test_f1_macro']))\n",
    "print(statistics.stdev(cv10_results['test_f1_macro']))\n",
    "print(statistics.mean(cv10_results['test_precision']))\n",
    "print(statistics.stdev(cv10_results['test_precision']))\n",
    "print(statistics.mean(cv10_results['test_recall']))\n",
    "print(statistics.stdev(cv10_results['test_recall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d13e321a-2bf9-47f3-a4a6-c9dd1e4aec80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm starting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\"'n_jobs' > 1 does not have any effect when\"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.0281353791555\n"
     ]
    }
   ],
   "source": [
    "solvers = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "jobs = [-1]\n",
    "maxiter = [100, 500, 1000]\n",
    "c = [10, 1, 0.1]\n",
    "param_grid={'classifier__C':c, 'classifier__solver':solvers, 'classifier__n_jobs':jobs, 'classifier__max_iter':maxiter}\n",
    "grid_clf = GridSearchCV(clf, param_grid, n_jobs=-1)\n",
    "start = time.time()\n",
    "print(\"I'm starting!\")\n",
    "grid_clf.fit(review_features, np.ravel(y))\n",
    "end = time.time()\n",
    "print((end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cea6b793-832b-4a98-bb2b-95193533a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_group_df.to_json(r'../devided_dataset_v2/CDs_and_Vinyl/train/cleaned_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "562fb612-31e0-43a7-9a47-cca8d896d3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>param_classifier__n_jobs</th>\n",
       "      <th>param_classifier__solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.314274</td>\n",
       "      <td>2.773403</td>\n",
       "      <td>22.106461</td>\n",
       "      <td>0.789819</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575093</td>\n",
       "      <td>0.573276</td>\n",
       "      <td>0.584527</td>\n",
       "      <td>0.579676</td>\n",
       "      <td>0.584987</td>\n",
       "      <td>0.579512</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215.385077</td>\n",
       "      <td>9.125162</td>\n",
       "      <td>20.650041</td>\n",
       "      <td>0.633041</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575162</td>\n",
       "      <td>0.573206</td>\n",
       "      <td>0.584457</td>\n",
       "      <td>0.579746</td>\n",
       "      <td>0.585057</td>\n",
       "      <td>0.579526</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127.930750</td>\n",
       "      <td>3.097294</td>\n",
       "      <td>23.014140</td>\n",
       "      <td>0.660145</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.576770</td>\n",
       "      <td>0.575302</td>\n",
       "      <td>0.584108</td>\n",
       "      <td>0.583240</td>\n",
       "      <td>0.584428</td>\n",
       "      <td>0.580770</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180.960551</td>\n",
       "      <td>4.390096</td>\n",
       "      <td>22.591533</td>\n",
       "      <td>0.792428</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.585296</td>\n",
       "      <td>0.589489</td>\n",
       "      <td>0.594381</td>\n",
       "      <td>0.596310</td>\n",
       "      <td>0.595401</td>\n",
       "      <td>0.592175</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190.735928</td>\n",
       "      <td>6.145154</td>\n",
       "      <td>22.109327</td>\n",
       "      <td>1.555230</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.592564</td>\n",
       "      <td>0.598504</td>\n",
       "      <td>0.603536</td>\n",
       "      <td>0.603928</td>\n",
       "      <td>0.603998</td>\n",
       "      <td>0.600506</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>148.245815</td>\n",
       "      <td>5.060626</td>\n",
       "      <td>23.119408</td>\n",
       "      <td>0.548793</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575093</td>\n",
       "      <td>0.573276</td>\n",
       "      <td>0.584527</td>\n",
       "      <td>0.579676</td>\n",
       "      <td>0.584987</td>\n",
       "      <td>0.579512</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209.577232</td>\n",
       "      <td>9.761099</td>\n",
       "      <td>23.340993</td>\n",
       "      <td>0.487204</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575162</td>\n",
       "      <td>0.573206</td>\n",
       "      <td>0.584457</td>\n",
       "      <td>0.579746</td>\n",
       "      <td>0.585057</td>\n",
       "      <td>0.579526</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>277.310260</td>\n",
       "      <td>1.043650</td>\n",
       "      <td>23.895615</td>\n",
       "      <td>0.333598</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575232</td>\n",
       "      <td>0.573345</td>\n",
       "      <td>0.584597</td>\n",
       "      <td>0.579676</td>\n",
       "      <td>0.585057</td>\n",
       "      <td>0.579582</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>684.006727</td>\n",
       "      <td>4.841569</td>\n",
       "      <td>26.239602</td>\n",
       "      <td>1.332473</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575232</td>\n",
       "      <td>0.578447</td>\n",
       "      <td>0.587393</td>\n",
       "      <td>0.582821</td>\n",
       "      <td>0.587294</td>\n",
       "      <td>0.582237</td>\n",
       "      <td>0.004815</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>683.569998</td>\n",
       "      <td>55.728508</td>\n",
       "      <td>24.401188</td>\n",
       "      <td>1.039373</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.577049</td>\n",
       "      <td>0.581243</td>\n",
       "      <td>0.588161</td>\n",
       "      <td>0.586455</td>\n",
       "      <td>0.590858</td>\n",
       "      <td>0.584753</td>\n",
       "      <td>0.004969</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>160.303679</td>\n",
       "      <td>2.707484</td>\n",
       "      <td>23.397562</td>\n",
       "      <td>0.418562</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575093</td>\n",
       "      <td>0.573276</td>\n",
       "      <td>0.584527</td>\n",
       "      <td>0.579676</td>\n",
       "      <td>0.584987</td>\n",
       "      <td>0.579512</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>225.466518</td>\n",
       "      <td>6.702446</td>\n",
       "      <td>23.784108</td>\n",
       "      <td>0.952808</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575162</td>\n",
       "      <td>0.573206</td>\n",
       "      <td>0.584457</td>\n",
       "      <td>0.579746</td>\n",
       "      <td>0.585057</td>\n",
       "      <td>0.579526</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>279.971987</td>\n",
       "      <td>9.356839</td>\n",
       "      <td>24.890300</td>\n",
       "      <td>0.545346</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575162</td>\n",
       "      <td>0.573345</td>\n",
       "      <td>0.584597</td>\n",
       "      <td>0.579676</td>\n",
       "      <td>0.584987</td>\n",
       "      <td>0.579554</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1315.569345</td>\n",
       "      <td>4.523879</td>\n",
       "      <td>24.691352</td>\n",
       "      <td>1.012167</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.574254</td>\n",
       "      <td>0.575582</td>\n",
       "      <td>0.585645</td>\n",
       "      <td>0.580514</td>\n",
       "      <td>0.585197</td>\n",
       "      <td>0.580239</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1261.837157</td>\n",
       "      <td>143.115322</td>\n",
       "      <td>23.059674</td>\n",
       "      <td>0.664940</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.575093</td>\n",
       "      <td>0.578447</td>\n",
       "      <td>0.587323</td>\n",
       "      <td>0.583170</td>\n",
       "      <td>0.587364</td>\n",
       "      <td>0.582279</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>129.824447</td>\n",
       "      <td>2.626486</td>\n",
       "      <td>23.058131</td>\n",
       "      <td>0.428136</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.596338</td>\n",
       "      <td>0.601789</td>\n",
       "      <td>0.602320</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.599164</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>192.961236</td>\n",
       "      <td>7.431702</td>\n",
       "      <td>23.003639</td>\n",
       "      <td>1.451489</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.593123</td>\n",
       "      <td>0.596408</td>\n",
       "      <td>0.601510</td>\n",
       "      <td>0.602320</td>\n",
       "      <td>0.602390</td>\n",
       "      <td>0.599150</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>129.753568</td>\n",
       "      <td>4.628526</td>\n",
       "      <td>22.596013</td>\n",
       "      <td>0.958893</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.592494</td>\n",
       "      <td>0.596548</td>\n",
       "      <td>0.602418</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.599108</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>189.399914</td>\n",
       "      <td>2.432357</td>\n",
       "      <td>22.915490</td>\n",
       "      <td>0.445306</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.594800</td>\n",
       "      <td>0.597456</td>\n",
       "      <td>0.604305</td>\n",
       "      <td>0.603788</td>\n",
       "      <td>0.603019</td>\n",
       "      <td>0.600674</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>197.780428</td>\n",
       "      <td>4.488208</td>\n",
       "      <td>22.802905</td>\n",
       "      <td>0.542448</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.599483</td>\n",
       "      <td>0.602348</td>\n",
       "      <td>0.608428</td>\n",
       "      <td>0.608051</td>\n",
       "      <td>0.610428</td>\n",
       "      <td>0.605748</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>119.855506</td>\n",
       "      <td>4.715703</td>\n",
       "      <td>21.667306</td>\n",
       "      <td>1.274124</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 5...</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.596338</td>\n",
       "      <td>0.601789</td>\n",
       "      <td>0.602320</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.599164</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>180.385156</td>\n",
       "      <td>9.442668</td>\n",
       "      <td>23.380077</td>\n",
       "      <td>0.939021</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 5...</td>\n",
       "      <td>0.593123</td>\n",
       "      <td>0.596408</td>\n",
       "      <td>0.601510</td>\n",
       "      <td>0.602320</td>\n",
       "      <td>0.602390</td>\n",
       "      <td>0.599150</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>176.656320</td>\n",
       "      <td>12.183475</td>\n",
       "      <td>22.646249</td>\n",
       "      <td>1.650279</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 5...</td>\n",
       "      <td>0.593193</td>\n",
       "      <td>0.596408</td>\n",
       "      <td>0.601510</td>\n",
       "      <td>0.602320</td>\n",
       "      <td>0.602111</td>\n",
       "      <td>0.599108</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>672.728368</td>\n",
       "      <td>22.426378</td>\n",
       "      <td>23.587984</td>\n",
       "      <td>1.521680</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 5...</td>\n",
       "      <td>0.592914</td>\n",
       "      <td>0.595569</td>\n",
       "      <td>0.602278</td>\n",
       "      <td>0.601901</td>\n",
       "      <td>0.601971</td>\n",
       "      <td>0.598927</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>586.440296</td>\n",
       "      <td>89.618512</td>\n",
       "      <td>22.988412</td>\n",
       "      <td>1.206362</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 5...</td>\n",
       "      <td>0.593053</td>\n",
       "      <td>0.595499</td>\n",
       "      <td>0.602488</td>\n",
       "      <td>0.602250</td>\n",
       "      <td>0.602181</td>\n",
       "      <td>0.599094</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>123.765706</td>\n",
       "      <td>1.363677</td>\n",
       "      <td>23.002641</td>\n",
       "      <td>0.749682</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.596338</td>\n",
       "      <td>0.601789</td>\n",
       "      <td>0.602320</td>\n",
       "      <td>0.602041</td>\n",
       "      <td>0.599164</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200.144873</td>\n",
       "      <td>6.545087</td>\n",
       "      <td>23.975093</td>\n",
       "      <td>1.571195</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.593123</td>\n",
       "      <td>0.596408</td>\n",
       "      <td>0.601510</td>\n",
       "      <td>0.602320</td>\n",
       "      <td>0.602390</td>\n",
       "      <td>0.599150</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>179.577173</td>\n",
       "      <td>6.682630</td>\n",
       "      <td>22.627903</td>\n",
       "      <td>0.454247</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.593193</td>\n",
       "      <td>0.596408</td>\n",
       "      <td>0.601510</td>\n",
       "      <td>0.602320</td>\n",
       "      <td>0.602111</td>\n",
       "      <td>0.599108</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>701.378030</td>\n",
       "      <td>52.336146</td>\n",
       "      <td>25.027211</td>\n",
       "      <td>3.024152</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.593053</td>\n",
       "      <td>0.595849</td>\n",
       "      <td>0.602278</td>\n",
       "      <td>0.601901</td>\n",
       "      <td>0.601971</td>\n",
       "      <td>0.599010</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>615.567887</td>\n",
       "      <td>124.230384</td>\n",
       "      <td>21.998522</td>\n",
       "      <td>0.395926</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.592774</td>\n",
       "      <td>0.595010</td>\n",
       "      <td>0.602488</td>\n",
       "      <td>0.602250</td>\n",
       "      <td>0.602111</td>\n",
       "      <td>0.598927</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>112.291488</td>\n",
       "      <td>1.653349</td>\n",
       "      <td>22.385432</td>\n",
       "      <td>0.452492</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629254</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.632094</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.631564</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>161.893972</td>\n",
       "      <td>2.611000</td>\n",
       "      <td>23.535739</td>\n",
       "      <td>1.964426</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.628905</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.635055</td>\n",
       "      <td>0.632513</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>0.631760</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>116.751959</td>\n",
       "      <td>8.990817</td>\n",
       "      <td>21.886844</td>\n",
       "      <td>0.831243</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.628905</td>\n",
       "      <td>0.626319</td>\n",
       "      <td>0.635055</td>\n",
       "      <td>0.632443</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>0.631732</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>176.109831</td>\n",
       "      <td>7.510592</td>\n",
       "      <td>22.916852</td>\n",
       "      <td>0.450370</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629324</td>\n",
       "      <td>0.625830</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.632164</td>\n",
       "      <td>0.635309</td>\n",
       "      <td>0.631383</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>189.822708</td>\n",
       "      <td>2.873495</td>\n",
       "      <td>22.000569</td>\n",
       "      <td>0.639006</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629115</td>\n",
       "      <td>0.625341</td>\n",
       "      <td>0.634216</td>\n",
       "      <td>0.632443</td>\n",
       "      <td>0.635239</td>\n",
       "      <td>0.631271</td>\n",
       "      <td>0.003623</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>106.549107</td>\n",
       "      <td>4.258540</td>\n",
       "      <td>21.217978</td>\n",
       "      <td>0.415892</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629254</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.632094</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.631564</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>147.374346</td>\n",
       "      <td>6.494432</td>\n",
       "      <td>21.218375</td>\n",
       "      <td>0.717881</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.628905</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.635055</td>\n",
       "      <td>0.632513</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>0.631760</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>120.087880</td>\n",
       "      <td>7.009665</td>\n",
       "      <td>21.466736</td>\n",
       "      <td>2.109538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.628905</td>\n",
       "      <td>0.626319</td>\n",
       "      <td>0.635055</td>\n",
       "      <td>0.632443</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>0.631732</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>552.906220</td>\n",
       "      <td>23.149613</td>\n",
       "      <td>25.057336</td>\n",
       "      <td>2.511190</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629045</td>\n",
       "      <td>0.626459</td>\n",
       "      <td>0.634566</td>\n",
       "      <td>0.632304</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.631634</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>649.073376</td>\n",
       "      <td>64.044718</td>\n",
       "      <td>22.847776</td>\n",
       "      <td>0.625885</td>\n",
       "      <td>0.1</td>\n",
       "      <td>500</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629744</td>\n",
       "      <td>0.625690</td>\n",
       "      <td>0.634356</td>\n",
       "      <td>0.631884</td>\n",
       "      <td>0.635519</td>\n",
       "      <td>0.631438</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>116.862296</td>\n",
       "      <td>6.661015</td>\n",
       "      <td>23.778924</td>\n",
       "      <td>0.905384</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629254</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.632094</td>\n",
       "      <td>0.635798</td>\n",
       "      <td>0.631564</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>154.105372</td>\n",
       "      <td>2.988240</td>\n",
       "      <td>22.756459</td>\n",
       "      <td>0.515107</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.628905</td>\n",
       "      <td>0.626389</td>\n",
       "      <td>0.635055</td>\n",
       "      <td>0.632513</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>0.631760</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>122.173402</td>\n",
       "      <td>3.568296</td>\n",
       "      <td>22.258772</td>\n",
       "      <td>0.742307</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.628905</td>\n",
       "      <td>0.626319</td>\n",
       "      <td>0.635055</td>\n",
       "      <td>0.632443</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>0.631732</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>542.668874</td>\n",
       "      <td>18.726043</td>\n",
       "      <td>24.404437</td>\n",
       "      <td>2.913416</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629045</td>\n",
       "      <td>0.626459</td>\n",
       "      <td>0.634566</td>\n",
       "      <td>0.632304</td>\n",
       "      <td>0.635728</td>\n",
       "      <td>0.631620</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>616.824113</td>\n",
       "      <td>151.850740</td>\n",
       "      <td>12.995213</td>\n",
       "      <td>3.064620</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>-1</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.629324</td>\n",
       "      <td>0.626529</td>\n",
       "      <td>0.634356</td>\n",
       "      <td>0.632024</td>\n",
       "      <td>0.635658</td>\n",
       "      <td>0.631578</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      175.314274      2.773403        22.106461        0.789819   \n",
       "1      215.385077      9.125162        20.650041        0.633041   \n",
       "2      127.930750      3.097294        23.014140        0.660145   \n",
       "3      180.960551      4.390096        22.591533        0.792428   \n",
       "4      190.735928      6.145154        22.109327        1.555230   \n",
       "5      148.245815      5.060626        23.119408        0.548793   \n",
       "6      209.577232      9.761099        23.340993        0.487204   \n",
       "7      277.310260      1.043650        23.895615        0.333598   \n",
       "8      684.006727      4.841569        26.239602        1.332473   \n",
       "9      683.569998     55.728508        24.401188        1.039373   \n",
       "10     160.303679      2.707484        23.397562        0.418562   \n",
       "11     225.466518      6.702446        23.784108        0.952808   \n",
       "12     279.971987      9.356839        24.890300        0.545346   \n",
       "13    1315.569345      4.523879        24.691352        1.012167   \n",
       "14    1261.837157    143.115322        23.059674        0.664940   \n",
       "15     129.824447      2.626486        23.058131        0.428136   \n",
       "16     192.961236      7.431702        23.003639        1.451489   \n",
       "17     129.753568      4.628526        22.596013        0.958893   \n",
       "18     189.399914      2.432357        22.915490        0.445306   \n",
       "19     197.780428      4.488208        22.802905        0.542448   \n",
       "20     119.855506      4.715703        21.667306        1.274124   \n",
       "21     180.385156      9.442668        23.380077        0.939021   \n",
       "22     176.656320     12.183475        22.646249        1.650279   \n",
       "23     672.728368     22.426378        23.587984        1.521680   \n",
       "24     586.440296     89.618512        22.988412        1.206362   \n",
       "25     123.765706      1.363677        23.002641        0.749682   \n",
       "26     200.144873      6.545087        23.975093        1.571195   \n",
       "27     179.577173      6.682630        22.627903        0.454247   \n",
       "28     701.378030     52.336146        25.027211        3.024152   \n",
       "29     615.567887    124.230384        21.998522        0.395926   \n",
       "30     112.291488      1.653349        22.385432        0.452492   \n",
       "31     161.893972      2.611000        23.535739        1.964426   \n",
       "32     116.751959      8.990817        21.886844        0.831243   \n",
       "33     176.109831      7.510592        22.916852        0.450370   \n",
       "34     189.822708      2.873495        22.000569        0.639006   \n",
       "35     106.549107      4.258540        21.217978        0.415892   \n",
       "36     147.374346      6.494432        21.218375        0.717881   \n",
       "37     120.087880      7.009665        21.466736        2.109538   \n",
       "38     552.906220     23.149613        25.057336        2.511190   \n",
       "39     649.073376     64.044718        22.847776        0.625885   \n",
       "40     116.862296      6.661015        23.778924        0.905384   \n",
       "41     154.105372      2.988240        22.756459        0.515107   \n",
       "42     122.173402      3.568296        22.258772        0.742307   \n",
       "43     542.668874     18.726043        24.404437        2.913416   \n",
       "44     616.824113    151.850740        12.995213        3.064620   \n",
       "\n",
       "   param_classifier__C param_classifier__max_iter param_classifier__n_jobs  \\\n",
       "0                   10                        100                       -1   \n",
       "1                   10                        100                       -1   \n",
       "2                   10                        100                       -1   \n",
       "3                   10                        100                       -1   \n",
       "4                   10                        100                       -1   \n",
       "5                   10                        500                       -1   \n",
       "6                   10                        500                       -1   \n",
       "7                   10                        500                       -1   \n",
       "8                   10                        500                       -1   \n",
       "9                   10                        500                       -1   \n",
       "10                  10                       1000                       -1   \n",
       "11                  10                       1000                       -1   \n",
       "12                  10                       1000                       -1   \n",
       "13                  10                       1000                       -1   \n",
       "14                  10                       1000                       -1   \n",
       "15                   1                        100                       -1   \n",
       "16                   1                        100                       -1   \n",
       "17                   1                        100                       -1   \n",
       "18                   1                        100                       -1   \n",
       "19                   1                        100                       -1   \n",
       "20                   1                        500                       -1   \n",
       "21                   1                        500                       -1   \n",
       "22                   1                        500                       -1   \n",
       "23                   1                        500                       -1   \n",
       "24                   1                        500                       -1   \n",
       "25                   1                       1000                       -1   \n",
       "26                   1                       1000                       -1   \n",
       "27                   1                       1000                       -1   \n",
       "28                   1                       1000                       -1   \n",
       "29                   1                       1000                       -1   \n",
       "30                 0.1                        100                       -1   \n",
       "31                 0.1                        100                       -1   \n",
       "32                 0.1                        100                       -1   \n",
       "33                 0.1                        100                       -1   \n",
       "34                 0.1                        100                       -1   \n",
       "35                 0.1                        500                       -1   \n",
       "36                 0.1                        500                       -1   \n",
       "37                 0.1                        500                       -1   \n",
       "38                 0.1                        500                       -1   \n",
       "39                 0.1                        500                       -1   \n",
       "40                 0.1                       1000                       -1   \n",
       "41                 0.1                       1000                       -1   \n",
       "42                 0.1                       1000                       -1   \n",
       "43                 0.1                       1000                       -1   \n",
       "44                 0.1                       1000                       -1   \n",
       "\n",
       "   param_classifier__solver  \\\n",
       "0                 liblinear   \n",
       "1                 newton-cg   \n",
       "2                     lbfgs   \n",
       "3                       sag   \n",
       "4                      saga   \n",
       "5                 liblinear   \n",
       "6                 newton-cg   \n",
       "7                     lbfgs   \n",
       "8                       sag   \n",
       "9                      saga   \n",
       "10                liblinear   \n",
       "11                newton-cg   \n",
       "12                    lbfgs   \n",
       "13                      sag   \n",
       "14                     saga   \n",
       "15                liblinear   \n",
       "16                newton-cg   \n",
       "17                    lbfgs   \n",
       "18                      sag   \n",
       "19                     saga   \n",
       "20                liblinear   \n",
       "21                newton-cg   \n",
       "22                    lbfgs   \n",
       "23                      sag   \n",
       "24                     saga   \n",
       "25                liblinear   \n",
       "26                newton-cg   \n",
       "27                    lbfgs   \n",
       "28                      sag   \n",
       "29                     saga   \n",
       "30                liblinear   \n",
       "31                newton-cg   \n",
       "32                    lbfgs   \n",
       "33                      sag   \n",
       "34                     saga   \n",
       "35                liblinear   \n",
       "36                newton-cg   \n",
       "37                    lbfgs   \n",
       "38                      sag   \n",
       "39                     saga   \n",
       "40                liblinear   \n",
       "41                newton-cg   \n",
       "42                    lbfgs   \n",
       "43                      sag   \n",
       "44                     saga   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'classifier__C': 10, 'classifier__max_iter': ...           0.575093   \n",
       "1   {'classifier__C': 10, 'classifier__max_iter': ...           0.575162   \n",
       "2   {'classifier__C': 10, 'classifier__max_iter': ...           0.576770   \n",
       "3   {'classifier__C': 10, 'classifier__max_iter': ...           0.585296   \n",
       "4   {'classifier__C': 10, 'classifier__max_iter': ...           0.592564   \n",
       "5   {'classifier__C': 10, 'classifier__max_iter': ...           0.575093   \n",
       "6   {'classifier__C': 10, 'classifier__max_iter': ...           0.575162   \n",
       "7   {'classifier__C': 10, 'classifier__max_iter': ...           0.575232   \n",
       "8   {'classifier__C': 10, 'classifier__max_iter': ...           0.575232   \n",
       "9   {'classifier__C': 10, 'classifier__max_iter': ...           0.577049   \n",
       "10  {'classifier__C': 10, 'classifier__max_iter': ...           0.575093   \n",
       "11  {'classifier__C': 10, 'classifier__max_iter': ...           0.575162   \n",
       "12  {'classifier__C': 10, 'classifier__max_iter': ...           0.575162   \n",
       "13  {'classifier__C': 10, 'classifier__max_iter': ...           0.574254   \n",
       "14  {'classifier__C': 10, 'classifier__max_iter': ...           0.575093   \n",
       "15  {'classifier__C': 1, 'classifier__max_iter': 1...           0.593333   \n",
       "16  {'classifier__C': 1, 'classifier__max_iter': 1...           0.593123   \n",
       "17  {'classifier__C': 1, 'classifier__max_iter': 1...           0.592494   \n",
       "18  {'classifier__C': 1, 'classifier__max_iter': 1...           0.594800   \n",
       "19  {'classifier__C': 1, 'classifier__max_iter': 1...           0.599483   \n",
       "20  {'classifier__C': 1, 'classifier__max_iter': 5...           0.593333   \n",
       "21  {'classifier__C': 1, 'classifier__max_iter': 5...           0.593123   \n",
       "22  {'classifier__C': 1, 'classifier__max_iter': 5...           0.593193   \n",
       "23  {'classifier__C': 1, 'classifier__max_iter': 5...           0.592914   \n",
       "24  {'classifier__C': 1, 'classifier__max_iter': 5...           0.593053   \n",
       "25  {'classifier__C': 1, 'classifier__max_iter': 1...           0.593333   \n",
       "26  {'classifier__C': 1, 'classifier__max_iter': 1...           0.593123   \n",
       "27  {'classifier__C': 1, 'classifier__max_iter': 1...           0.593193   \n",
       "28  {'classifier__C': 1, 'classifier__max_iter': 1...           0.593053   \n",
       "29  {'classifier__C': 1, 'classifier__max_iter': 1...           0.592774   \n",
       "30  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629254   \n",
       "31  {'classifier__C': 0.1, 'classifier__max_iter':...           0.628905   \n",
       "32  {'classifier__C': 0.1, 'classifier__max_iter':...           0.628905   \n",
       "33  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629324   \n",
       "34  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629115   \n",
       "35  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629254   \n",
       "36  {'classifier__C': 0.1, 'classifier__max_iter':...           0.628905   \n",
       "37  {'classifier__C': 0.1, 'classifier__max_iter':...           0.628905   \n",
       "38  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629045   \n",
       "39  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629744   \n",
       "40  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629254   \n",
       "41  {'classifier__C': 0.1, 'classifier__max_iter':...           0.628905   \n",
       "42  {'classifier__C': 0.1, 'classifier__max_iter':...           0.628905   \n",
       "43  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629045   \n",
       "44  {'classifier__C': 0.1, 'classifier__max_iter':...           0.629324   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.573276           0.584527           0.579676   \n",
       "1            0.573206           0.584457           0.579746   \n",
       "2            0.575302           0.584108           0.583240   \n",
       "3            0.589489           0.594381           0.596310   \n",
       "4            0.598504           0.603536           0.603928   \n",
       "5            0.573276           0.584527           0.579676   \n",
       "6            0.573206           0.584457           0.579746   \n",
       "7            0.573345           0.584597           0.579676   \n",
       "8            0.578447           0.587393           0.582821   \n",
       "9            0.581243           0.588161           0.586455   \n",
       "10           0.573276           0.584527           0.579676   \n",
       "11           0.573206           0.584457           0.579746   \n",
       "12           0.573345           0.584597           0.579676   \n",
       "13           0.575582           0.585645           0.580514   \n",
       "14           0.578447           0.587323           0.583170   \n",
       "15           0.596338           0.601789           0.602320   \n",
       "16           0.596408           0.601510           0.602320   \n",
       "17           0.596548           0.602418           0.602041   \n",
       "18           0.597456           0.604305           0.603788   \n",
       "19           0.602348           0.608428           0.608051   \n",
       "20           0.596338           0.601789           0.602320   \n",
       "21           0.596408           0.601510           0.602320   \n",
       "22           0.596408           0.601510           0.602320   \n",
       "23           0.595569           0.602278           0.601901   \n",
       "24           0.595499           0.602488           0.602250   \n",
       "25           0.596338           0.601789           0.602320   \n",
       "26           0.596408           0.601510           0.602320   \n",
       "27           0.596408           0.601510           0.602320   \n",
       "28           0.595849           0.602278           0.601901   \n",
       "29           0.595010           0.602488           0.602250   \n",
       "30           0.626389           0.634286           0.632094   \n",
       "31           0.626389           0.635055           0.632513   \n",
       "32           0.626319           0.635055           0.632443   \n",
       "33           0.625830           0.634286           0.632164   \n",
       "34           0.625341           0.634216           0.632443   \n",
       "35           0.626389           0.634286           0.632094   \n",
       "36           0.626389           0.635055           0.632513   \n",
       "37           0.626319           0.635055           0.632443   \n",
       "38           0.626459           0.634566           0.632304   \n",
       "39           0.625690           0.634356           0.631884   \n",
       "40           0.626389           0.634286           0.632094   \n",
       "41           0.626389           0.635055           0.632513   \n",
       "42           0.626319           0.635055           0.632443   \n",
       "43           0.626459           0.634566           0.632304   \n",
       "44           0.626529           0.634356           0.632024   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.584987         0.579512        0.004766               43  \n",
       "1            0.585057         0.579526        0.004774               40  \n",
       "2            0.584428         0.580770        0.003912               36  \n",
       "3            0.595401         0.592175        0.004169               32  \n",
       "4            0.603998         0.600506        0.004476               18  \n",
       "5            0.584987         0.579512        0.004766               43  \n",
       "6            0.585057         0.579526        0.004774               40  \n",
       "7            0.585057         0.579582        0.004753               38  \n",
       "8            0.587294         0.582237        0.004815               35  \n",
       "9            0.590858         0.584753        0.004969               33  \n",
       "10           0.584987         0.579512        0.004766               43  \n",
       "11           0.585057         0.579526        0.004774               40  \n",
       "12           0.584987         0.579554        0.004750               39  \n",
       "13           0.585197         0.580239        0.004720               37  \n",
       "14           0.587364         0.582279        0.004867               34  \n",
       "15           0.602041         0.599164        0.003664               19  \n",
       "16           0.602390         0.599150        0.003741               22  \n",
       "17           0.602041         0.599108        0.003961               27  \n",
       "18           0.603019         0.600674        0.003827               17  \n",
       "19           0.610428         0.605748        0.004128               16  \n",
       "20           0.602041         0.599164        0.003664               19  \n",
       "21           0.602390         0.599150        0.003741               22  \n",
       "22           0.602111         0.599108        0.003671               25  \n",
       "23           0.601971         0.598927        0.003919               31  \n",
       "24           0.602181         0.599094        0.004011               28  \n",
       "25           0.602041         0.599164        0.003664               19  \n",
       "26           0.602390         0.599150        0.003741               22  \n",
       "27           0.602111         0.599108        0.003671               25  \n",
       "28           0.601971         0.599010        0.003828               29  \n",
       "29           0.602111         0.598927        0.004173               30  \n",
       "30           0.635798         0.631564        0.003398               10  \n",
       "31           0.635938         0.631760        0.003630                1  \n",
       "32           0.635938         0.631732        0.003648                4  \n",
       "33           0.635309         0.631383        0.003450               14  \n",
       "34           0.635239         0.631271        0.003623               15  \n",
       "35           0.635798         0.631564        0.003398               10  \n",
       "36           0.635938         0.631760        0.003630                1  \n",
       "37           0.635938         0.631732        0.003648                4  \n",
       "38           0.635798         0.631634        0.003460                7  \n",
       "39           0.635519         0.631438        0.003501               13  \n",
       "40           0.635798         0.631564        0.003398               10  \n",
       "41           0.635938         0.631760        0.003630                1  \n",
       "42           0.635938         0.631732        0.003648                4  \n",
       "43           0.635728         0.631620        0.003444                8  \n",
       "44           0.635658         0.631578        0.003321                9  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(grid_clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd032e-2505-4180-941e-aa55e34aa53e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccd2b721",
   "metadata": {},
   "source": [
    "All the older stuff is below here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4f9117d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 71540 71541 71542]\n",
      "  Test:  index=[    7    10    21 ... 71512 71515 71520]\n",
      "model score: 0.569\n",
      "46.16732168197632\n",
      "Fold 1:\n",
      "  Train: index=[    0     1     2 ... 71540 71541 71542]\n",
      "  Test:  index=[    3     4    11 ... 71526 71530 71538]\n",
      "model score: 0.579\n",
      "43.28184628486633\n",
      "Fold 2:\n",
      "  Train: index=[    0     1     2 ... 71540 71541 71542]\n",
      "  Test:  index=[    8    16    30 ... 71504 71525 71527]\n",
      "model score: 0.578\n",
      "48.57866644859314\n",
      "Fold 3:\n",
      "  Train: index=[    0     1     2 ... 71539 71540 71542]\n",
      "  Test:  index=[   25    27    44 ... 71487 71505 71541]\n",
      "model score: 0.579\n",
      "43.54520773887634\n",
      "Fold 4:\n",
      "  Train: index=[    1     2     3 ... 71540 71541 71542]\n",
      "  Test:  index=[    0    12    15 ... 71536 71537 71539]\n",
      "model score: 0.568\n",
      "48.14018964767456\n",
      "Fold 5:\n",
      "  Train: index=[    0     1     2 ... 71539 71540 71541]\n",
      "  Test:  index=[   17    19    22 ... 71531 71535 71542]\n",
      "model score: 0.586\n",
      "50.04946684837341\n",
      "Fold 6:\n",
      "  Train: index=[    0     1     2 ... 71540 71541 71542]\n",
      "  Test:  index=[   14    20    35 ... 71497 71499 71521]\n",
      "model score: 0.583\n",
      "41.702008962631226\n",
      "Fold 7:\n",
      "  Train: index=[    0     1     2 ... 71539 71541 71542]\n",
      "  Test:  index=[    5     6    13 ... 71528 71532 71540]\n",
      "model score: 0.581\n",
      "55.94741368293762\n",
      "Fold 8:\n",
      "  Train: index=[    0     3     4 ... 71540 71541 71542]\n",
      "  Test:  index=[    1     2     9 ... 71514 71518 71533]\n",
      "model score: 0.571\n",
      "48.81972336769104\n",
      "Fold 9:\n",
      "  Train: index=[    0     1     2 ... 71540 71541 71542]\n",
      "  Test:  index=[   24    29    31 ... 71513 71524 71529]\n",
      "model score: 0.581\n",
      "52.01545572280884\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 10, shuffle = True)\n",
    "for i, (train_index, test_index) in enumerate(kf.split(review_features)):\n",
    "    start = time.time()\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "    x_train = review_features.loc[train_index, :]\n",
    "    x_test = review_features.loc[test_index, :]\n",
    "    y_train = np.ravel(y.loc[train_index, :])\n",
    "    y_test = np.ravel(y.loc[test_index,:])\n",
    "    \n",
    "    #x_train_features = wordbagger.fit_transform(x_train)\n",
    "    #x_test_features = wordbagger.fit_transform(x_test)\n",
    "    #scaler = preprocessing.MaxAbsScaler().fit(x_train_features)\n",
    "    #x_train_scaled = scaler.transform(x_train_features)\n",
    "    #print(type(y_train))\n",
    "    #print(x_train.shape)\n",
    "    #print(y_train.shape)\n",
    "    #clf = Pipeline(steps = [(\"preprocess\", preprocessor), ('classifier', LogisticRegression()) ])\n",
    "    clf.fit(x_train, y_train)\n",
    "    #print(x_train)\n",
    "    #print(y_train.shape)\n",
    "    #X_trans = preprocessor.fit_transform(x_train)\n",
    "    #print(x_train.shape)\n",
    "    print(\"model score: %.3f\" % clf.score(x_test, y_test))\n",
    "    end = time.time()\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493bb63e",
   "metadata": {},
   "source": [
    "NLP Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a38ef6d-1722-4684-9d96-93b6e5790cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I am being handed a list of documents\", \"Each of these documents has several unique words\", \"The words will represent the class of each review\", \"I am also removing stopwords in order to make this make more sense\"]\n",
    "cleaned_corpus = [transform_document(doc) for doc in corpus]\n",
    "vocabulary = vocabulary_from_corpus(cleaned_corpus, True)\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)), \n",
    "                 ('tfid', TfidfTransformer())]).fit(cleaned_corpus)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c8e5cb-dfb0-4602-b800-3f6cc25f0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords():\n",
    "    file = open('en.txt')\n",
    "    stopwords = []\n",
    "    for line in file:\n",
    "        stopwords.append(line.rstrip())\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4c4e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_corpus(review_group):\n",
    "    stopwords = get_stopwords()\n",
    "    reviewTextSet = review_group['reviewText']\n",
    "    for index in review_group.index:\n",
    "        curr_parsed = nlp(reviewTextSet[index].lower())\n",
    "        doclist = []\n",
    "        for token in curr_parsed:\n",
    "            lemma = token.lemma_\n",
    "            if not(re.match(\"[a-z0-9]+\", lemma)):\n",
    "                continue\n",
    "            if lemma not in stopwords:\n",
    "                doclist.append(lemma)\n",
    "        reviewTextSet[index] = \" \".join(doclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9a82e873-6a79-4d55-9c06-94041197a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_document(doc, remove_stopwords = True):\n",
    "    #new_doc = \"\"\n",
    "    stopwords = get_stopwords() # is this slow?\n",
    "    parsed_text = nlp(doc) # is this slow\n",
    "    doclist = []\n",
    "    for token in parsed_text:\n",
    "        lemma = token.lemma_.lower()\n",
    "        if re.match(\"[a-z0-9]+\", lemma) and (remove_stopwords == False or lemma not in stopwords):\n",
    "            doclist.append(lemma) # this is less slow?\n",
    "    return \" \".join(doclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "944f9414-c74e-4287-8756-74e82d279fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(review_text, remove_stopwords = True):\n",
    "    word_bag = {}\n",
    "    stopwords = get_stopwords()\n",
    "    parsed_text = nlp(review_text)\n",
    "    for token in parsed_text:\n",
    "        lemma = token.lemma_.lower()\n",
    "        if re.match(\"[a-z0-9]+\", lemma) and (remove_stopwords == False or lemma not in stopwords):\n",
    "            if lemma in word_bag:\n",
    "                word_bag[lemma] += 1\n",
    "            else:\n",
    "                word_bag[lemma] = 1\n",
    "    return word_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c054d665-1ac0-4e05-9826-b96a2bc4bb43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first', 'the', 'second', 'third', 'be', 'and', 'this', 'one', 'document']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vocabulary_from_corpus(corpus, remove_stopwords = True):\n",
    "    vocab_set = set()\n",
    "    for document in corpus:\n",
    "        word_bag = bag_of_words(document, remove_stopwords)\n",
    "        for word in word_bag.keys():\n",
    "            vocab_set.add(word)\n",
    "    return list(vocab_set)\n",
    "vocabulary_from_corpus(['this is the first document', 'this document is the second document', 'and this is the third one', 'is this the first document'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da656ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.read_json('../devided_dataset_v2/CDs_and_Vinyl/train/product_training.json')\n",
    "review_df = pd.read_json('../devided_dataset_v2/CDs_and_Vinyl/train/review_training.json')\n",
    "#len(product_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "098d8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "teststring = \"First, you need to preprocess the raw text data. This may involve tasks like tokenizing the text (i.e., splitting it into individual words), removing stopwords, stemming or lemmatizing the words, and converting the text into a numerical format that can be used as input for the model. Then, you need to split the data into training and testing sets. The training set will be used to train the model, while the testing set will be used to evaluate its performance.\"\n",
    "#teststring.lower()\n",
    "parsed = nlp(teststring.lower())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
