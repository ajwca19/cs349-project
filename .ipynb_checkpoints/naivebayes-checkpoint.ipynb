{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06a99b21-db3c-44bc-ba47-c72d4a4f235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca5b12a9-5bbc-4884-9edd-f0a75da71e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(path, test=False):\n",
    "    #create appropriate file path\n",
    "    if test == False:\n",
    "        pfilename = path + \"/product_training.json\"\n",
    "        rfilename = path + \"/review_training.json\"\n",
    "    else:\n",
    "        pfilename = path + \"/product_test.json\"\n",
    "        rfilename = path + \"/review_test.json\"\n",
    "    \n",
    "    #extract files as pandas dataframes\n",
    "    product_df = pd.read_json(pfilename)\n",
    "    review_df = pd.read_json(rfilename).drop_duplicates(subset=[\"reviewerID\", \"unixReviewTime\"], keep=\"first\")\n",
    "    grouped_reviews = review_df.groupby('asin')\n",
    "    \n",
    "    asin_review_data_dict = {}\n",
    "    for ind in product_df.index:\n",
    "        print(ind)\n",
    "        #review_group = grouped_reviews.get_group(review_df['asin'][ind])\n",
    "        #asin_review_data_dict.update({product_df['asin'][ind] : review_group})\n",
    "        \n",
    "    return (asin_review_data_dict, product_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddaf67f-9958-4427-852f-120974d5c5a9",
   "metadata": {},
   "source": [
    "PSEUDOCODE FOR WHAT WE NEED TO DO WITH THE TRAINING DATA:\n",
    " - Saahir/Amy starts by putting all of the reviews for a product in one string. This string is the DOCUMENT for the reviews of a product\n",
    " - I will then take the corpus and transform it to remove stopwords, punctuation, and lemmatize everything. This is the true \"bag of words\".\n",
    " - Then, I use the cleaned text data to train the Naive Bayes classifier\n",
    " - When we get test data, first clean in the same way, then use it in the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c8e5cb-dfb0-4602-b800-3f6cc25f0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords():\n",
    "    file = open('en.txt')\n",
    "    stopwords = []\n",
    "    for line in file:\n",
    "        stopwords.append(line.rstrip())\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a82e873-6a79-4d55-9c06-94041197a3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preprocess raw text datum involve task tokenize text i.e. split individual word remove stopword stem lemmatize word convert text numerical format input model split datum training testing set training set train model testing set evaluate performance'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_document(doc, remove_stopwords = True):\n",
    "    new_doc = \"\"\n",
    "    stopwords = get_stopwords()\n",
    "    parsed_text = nlp(doc)\n",
    "    for token in parsed_text:\n",
    "        lemma = token.lemma_.lower()\n",
    "        if re.match(\"[a-z0-9]+\", lemma) and (remove_stopwords == False or lemma not in stopwords):\n",
    "            new_doc += lemma + \" \"\n",
    "    return new_doc.rstrip()\n",
    "\n",
    "transform_document(\"First, you need to preprocess the raw text data. This may involve tasks like tokenizing the text (i.e., splitting it into individual words), removing stopwords, stemming or lemmatizing the words, and converting the text into a numerical format that can be used as input for the model. Then, you need to split the data into training and testing sets. The training set will be used to train the model, while the testing set will be used to evaluate its performance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944f9414-c74e-4287-8756-74e82d279fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(review_text, remove_stopwords = True):\n",
    "    word_bag = {}\n",
    "    stopwords = get_stopwords()\n",
    "    parsed_text = nlp(review_text)\n",
    "    for token in parsed_text:\n",
    "        lemma = token.lemma_.lower()\n",
    "        if re.match(\"[a-z0-9]+\", lemma) and (remove_stopwords == False or lemma not in stopwords):\n",
    "            if lemma in word_bag:\n",
    "                word_bag[lemma] += 1\n",
    "            else:\n",
    "                word_bag[lemma] = 1\n",
    "    return word_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c054d665-1ac0-4e05-9826-b96a2bc4bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hand list document document unique word word represent class review'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vocabulary_from_corpus(corpus, remove_stopwords = True):\n",
    "    vocab_set = set()\n",
    "    for document in corpus:\n",
    "        word_bag = bag_of_words(document, remove_stopwords)\n",
    "        for word in word_bag.keys():\n",
    "            vocab_set.add(word)\n",
    "    return list(vocab_set)\n",
    "\n",
    "def transform_document(doc, remove_stopwords = True):\n",
    "    new_doc = \"\"\n",
    "    stopwords = get_stopwords()\n",
    "    parsed_text = nlp(doc)\n",
    "    for token in parsed_text:\n",
    "        lemma = token.lemma_.lower()\n",
    "        if re.match(\"[a-z0-9]+\", lemma) and (remove_stopwords == False or lemma not in stopwords):\n",
    "            new_doc += lemma + \" \"\n",
    "    return new_doc.rstrip()\n",
    "\n",
    "vocabulary_from_corpus(['this is the first document', 'this document is the second document', 'and this is the third one', 'is this the first document'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a38ef6d-1722-4684-9d96-93b6e5790cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hand list document', 'document unique word', 'word represent class review', 'remove stopword order make make sense']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.91629073, 1.91629073, 1.91629073, 1.51082562, 1.91629073,\n",
       "       1.91629073, 1.51082562, 1.91629073, 1.91629073, 1.91629073,\n",
       "       1.91629073, 1.91629073, 1.91629073])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\"I am being handed a list of documents\", \"Each of these documents has several unique words\", \"The words will represent the class of each review\", \"I am also removing stopwords in order to make this make more sense\"]\n",
    "cleaned_corpus = [transform_document(doc) for doc in corpus]\n",
    "vocabulary = vocabulary_from_corpus(cleaned_corpus, True)\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)), ('tfid', TfidfTransformer())]).fit(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a2cfadc0-aa2e-4455-a879-eb6240951a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>awesomeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000B049F5B33CD310EB1AB236E20191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00018184A9EC4D270219A296B2580303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000281A9CAC43FF1F335726A390636DA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00030884DF109F325638A6BFD5B13CFF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000325BA25966B5FC701D5D2B5DBA4E0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73077</th>\n",
       "      <td>FFFDD3C72D23AF858D6E0ED92612370D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73078</th>\n",
       "      <td>FFFDDE284A73B29B320381487EC7DE9E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73079</th>\n",
       "      <td>FFFEB3EE2372807964F024707D50FB21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73080</th>\n",
       "      <td>FFFF4545AB232D81D0F9B208388BB7AA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73081</th>\n",
       "      <td>FFFF5A3D9CB0B40FF0FE6B95F05D26FE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73082 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   asin  awesomeness\n",
       "0      0000B049F5B33CD310EB1AB236E20191            1\n",
       "1      00018184A9EC4D270219A296B2580303            0\n",
       "2      000281A9CAC43FF1F335726A390636DA            0\n",
       "3      00030884DF109F325638A6BFD5B13CFF            1\n",
       "4      000325BA25966B5FC701D5D2B5DBA4E0            0\n",
       "...                                 ...          ...\n",
       "73077  FFFDD3C72D23AF858D6E0ED92612370D            1\n",
       "73078  FFFDDE284A73B29B320381487EC7DE9E            1\n",
       "73079  FFFEB3EE2372807964F024707D50FB21            0\n",
       "73080  FFFF4545AB232D81D0F9B208388BB7AA            1\n",
       "73081  FFFF5A3D9CB0B40FF0FE6B95F05D26FE            1\n",
       "\n",
       "[73082 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "86c92fbe-6af3-432f-8a0a-fff1ea309c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    asin                        reviewerID  \\\n",
      "0       6673F1740E03573BCD64238FE711FC69  9C856D4A18E1355783B3B28B7ECC1848   \n",
      "1       690819436E20BB31657AF6B58B984DD4  6E9ABBD26A27C2B2851D1EC34A01CBDC   \n",
      "2       A680D4753F0CEA2252C168A6ACB2B623  B637C3C93E61094474710F456928BE9F   \n",
      "3       F4A966F1FA340B16651D676BC246D227  AA7918E9410D650A076221C7B2934A09   \n",
      "4       EF59DAF0C00319A48D4784266FD157EE  2293C9B7950A3356B95828419A677720   \n",
      "...                                  ...                               ...   \n",
      "770764  DCDAF67A4FAE8E27E326464F7CEDC8BB  D9DD901F94F14726CEF1A8C13A926A90   \n",
      "770774  2052A31C7E1508382784EA8018AC0321  A95038A6A726B261A6C1F6357C7F4B4B   \n",
      "770777  D1252C5B6CB821FC38F5681FFEDE7424  067B15441E9FAD6BC033B1F2DA99587E   \n",
      "770782  9BC50277D18FAB423AD33C8CE4CC000D  EF922377A87E9D01F50065F2DA1722A8   \n",
      "770785  E4CDE9C72DB665961BE969B082806619  27FDC1E110DB45E1A7E0CCEABECF8632   \n",
      "\n",
      "        unixReviewTime  vote  verified   reviewTime  \\\n",
      "0           1451520000     9      True  12 31, 2015   \n",
      "1           1113523200     9     False  04 15, 2005   \n",
      "2           1126137600  None     False   09 8, 2005   \n",
      "3            954979200  None     False   04 6, 2000   \n",
      "4           1477958400  None      True   11 1, 2016   \n",
      "...                ...   ...       ...          ...   \n",
      "770764      1290816000  None     False  11 27, 2010   \n",
      "770774      1474934400  None      True  09 27, 2016   \n",
      "770777      1282867200  None     False  08 27, 2010   \n",
      "770782      1290556800  None     False  11 24, 2010   \n",
      "770785      1105401600  None     False  01 11, 2005   \n",
      "\n",
      "                            style                      reviewerName  \\\n",
      "0       {'Format:': ' MP3 Music'}  8D88BB79AAC50277AEE82FCFD77F6744   \n",
      "1        {'Format:': ' Audio CD'}  8DC0611245A871AC51BBEEBB85F33A58   \n",
      "2                            None  2259386624CFA0EC53A75A50A9BB57A5   \n",
      "3        {'Format:': ' Audio CD'}  7A65A155C993535BC99CBCB39E7161B5   \n",
      "4        {'Format:': ' Audio CD'}  C69A09446009C500B1364B7DB5510497   \n",
      "...                           ...                               ...   \n",
      "770764   {'Format:': ' Audio CD'}  F42508933A9DADC406D5010FFE98149D   \n",
      "770774   {'Format:': ' Audio CD'}  754F9E53085BDCC746E1F9EE53C72844   \n",
      "770777   {'Format:': ' Audio CD'}  94D644AB716093162A84FE4D60EEA75E   \n",
      "770782                       None  0441BC4F6B7BD180769FDCDD8E603560   \n",
      "770785   {'Format:': ' Audio CD'}  A7487BE472C2B632FCE5F097B47F5DE0   \n",
      "\n",
      "                                               reviewText  \\\n",
      "0       Finding the Beatles all over again - and bette...   \n",
      "1       These guys can sing!  Such classic tunes...poi...   \n",
      "2       Snoop Doggy Dogg made a classic album, DoggySt...   \n",
      "3       Stevie Nicks Has had Her Moments. I Like Some ...   \n",
      "4                                               Great cd.   \n",
      "...                                                   ...   \n",
      "770764  Almost eight years later, KOOP's \"Waltz for Ko...   \n",
      "770774  the remastering is excellent . I think we all ...   \n",
      "770777  --superb rockin' soul pop folk music.\\n--tunes...   \n",
      "770782  I have owned a CD copy of this show for at lea...   \n",
      "770785  Smile is Brian's gift to a sick and troubled w...   \n",
      "\n",
      "                                                  summary image  \n",
      "0       I sit listening - with my jaw to the floor - H...  None  \n",
      "1                                   Under Appreciated....  None  \n",
      "2                                              DoggyStyle  None  \n",
      "3                             Pretty Good but a Bit Dated  None  \n",
      "4                                              Five Stars  None  \n",
      "...                                                   ...   ...  \n",
      "770764                   This album never gets old for me  None  \n",
      "770774                                            At Last  None  \n",
      "770777                                        SHE'S TOPS!  None  \n",
      "770782                                    Forgettable R&H  None  \n",
      "770785               Music just doesn't get any better...  None  \n",
      "\n",
      "[519173 rows x 11 columns]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "40",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 40",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/42/1tm0lh9x4mq_b_x54vd3y4700000gn/T/ipykernel_4847/49648547.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mreview_group_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_df\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../devided_dataset_v2/CDs_and_Vinyl/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#review_group_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#review_group_dict['0000B049F5B33CD310EB1AB236E20191']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/42/1tm0lh9x4mq_b_x54vd3y4700000gn/T/ipykernel_4847/3170725538.py\u001b[0m in \u001b[0;36mdata_preprocessing\u001b[0;34m(path, test)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0masin_review_data_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mreview_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped_reviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0masin_review_data_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mproduct_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'asin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreview_group\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 40"
     ]
    }
   ],
   "source": [
    "(review_group_dict, product_df) = data_preprocessing(\"../devided_dataset_v2/CDs_and_Vinyl/train\")\n",
    "#review_group_dict\n",
    "#review_group_dict['0000B049F5B33CD310EB1AB236E20191']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e4f44-af61-48e2-b580-263b92383075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
